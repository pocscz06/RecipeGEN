{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "749de63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, firestore, storage\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3160cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cf044bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecipeImageDataset(Dataset):\n",
    "    def __init__(self, recipes_data, ingredient_mapping, transform=None):\n",
    "    \n",
    "        self.recipes = recipes_data\n",
    "        self.transform = transform\n",
    "        self.ingredient_to_idx = ingredient_mapping\n",
    "        self.idx_to_ingredient = {idx: ingredient for ingredient, idx in self.ingredient_to_idx.items()}\n",
    "        #Pre-compute labels to avoid doing this work during training\n",
    "        self.labels = []\n",
    "        for recipe in self.recipes:\n",
    "           \n",
    "            ingredients = recipe['ingredients']\n",
    "            ingredient_vector = torch.zeros(len(self.ingredient_to_idx))\n",
    "            \n",
    "            for ingredient in ingredients:\n",
    "                if ingredient in self.ingredient_to_idx:\n",
    "                    ingredient_vector[self.ingredient_to_idx[ingredient]] = 1.0\n",
    "            \n",
    "            self.labels.append(ingredient_vector)\n",
    "        \n",
    "        print(f\"Dataset created with {len(self.recipes)} recipes\")\n",
    "        print(f\"Total unique ingredients: {len(self.ingredient_to_idx)}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.recipes)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        recipe = self.recipes[idx]\n",
    "        image_url = recipe['image_url']\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        try:\n",
    "            #Load image from URL\n",
    "            response = requests.get(image_url)\n",
    "            img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "            \n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            \n",
    "            return img, label\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_url}: {e}\")\n",
    "            #Return a placeholder image in case of error\n",
    "            placeholder = torch.zeros(3, 224, 224)\n",
    "            return placeholder, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48fe3d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_from_firebase(firestore_client, test_size=0.2):\n",
    "    recipes = []\n",
    "    unique_ingredients = set()\n",
    "    \n",
    "    #Get all recipes from Firestore\n",
    "    recipes_ref = firestore_client.collection('recipes')\n",
    "    all_recipes = list(recipes_ref.stream())\n",
    "    \n",
    "    #Extract recipe data and collect unique ingredients\n",
    "    for recipe_doc in all_recipes:\n",
    "        recipe = recipe_doc.to_dict()\n",
    "        if ('image_url' in recipe and recipe['image_url'] and \n",
    "            'ingredients' in recipe and recipe['ingredients']):\n",
    "            recipes.append(recipe)\n",
    "            \n",
    "            #Collect unique ingredients\n",
    "            if isinstance(recipe['ingredients'], list):\n",
    "                unique_ingredients.update(recipe['ingredients'])\n",
    "    \n",
    "    #Create ingredient mapping\n",
    "    ingredient_to_idx = {ingredient: idx for idx, ingredient in enumerate(sorted(unique_ingredients))}\n",
    "    \n",
    "    #Train-test split\n",
    "    n_recipes = len(recipes)\n",
    "    indices = np.arange(n_recipes)\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    split_idx = int(n_recipes * (1 - test_size))\n",
    "    train_indices = indices[:split_idx]\n",
    "    test_indices = indices[split_idx:]\n",
    "    \n",
    "    #Select recipes for each split\n",
    "    train_recipes = [recipes[i] for i in train_indices]\n",
    "    test_recipes = [recipes[i] for i in test_indices]\n",
    "    \n",
    "    print(f\"Loaded {len(train_recipes)} recipes for training\")\n",
    "    print(f\"Loaded {len(test_recipes)} recipes for testing\")\n",
    "    print(f\"Total unique ingredients: {len(unique_ingredients)}\")\n",
    "    \n",
    "    return train_recipes, test_recipes, ingredient_to_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dca92cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IngredientRecognition(nn.Module):\n",
    "    def __init__(self, num_ingredients):\n",
    "        super(IngredientRecognition, self).__init__()\n",
    "        \n",
    "        #Load pre-trained EfficientNet\n",
    "        self.backbone = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.DEFAULT)\n",
    "        \n",
    "        #Freeze early layers\n",
    "        for param in list(self.backbone.parameters())[:-30]:\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        #Modify classifier for multi-label classification\n",
    "        num_ftrs = self.backbone.classifier[1].in_features\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.3, inplace=True),\n",
    "            nn.Linear(num_ftrs, num_ingredients),\n",
    "            nn.Sigmoid()  #Sigmoid for multi-label classification\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8e9e96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, \n",
    "                num_epochs=10, device='cuda'):\n",
    "    \n",
    "    best_val_f1 = 0.0\n",
    "    best_model_weights = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        #Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        \n",
    "        #Validation phase\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "        \n",
    "        for inputs, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "            \n",
    "            #Threshold predictions\n",
    "            threshold_preds = (outputs > 0.5).float()\n",
    "            \n",
    "            val_preds.extend(threshold_preds.cpu().numpy())\n",
    "            val_targets.extend(labels.cpu().numpy())\n",
    "        \n",
    "        #Calculate metrics\n",
    "        val_f1 = f1_score(\n",
    "            np.array(val_targets).flatten(), \n",
    "            np.array(val_preds).flatten(), \n",
    "            average='macro'\n",
    "        )\n",
    "        \n",
    "        val_precision = precision_score(\n",
    "            np.array(val_targets).flatten(), \n",
    "            np.array(val_preds).flatten(), \n",
    "            average='macro',\n",
    "            zero_division=0\n",
    "        )\n",
    "        \n",
    "        val_recall = recall_score(\n",
    "            np.array(val_targets).flatten(), \n",
    "            np.array(val_preds).flatten(), \n",
    "            average='macro',\n",
    "            zero_division=0\n",
    "        )\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f}, \"\n",
    "              f\"Val F1: {val_f1:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}\")\n",
    "        \n",
    "        #Save best model\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            best_model_weights = model.state_dict().copy()\n",
    "    \n",
    "    #Load best model weights\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10082990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recipe_by_ingredients(firestore_client, ingredients, top_k=3):\n",
    "    recipes_ref = firestore_client.collection('recipes')\n",
    "    all_recipes = list(recipes_ref.stream())\n",
    "    \n",
    "    matches = []\n",
    "    for recipe_doc in all_recipes:\n",
    "        recipe = recipe_doc.to_dict()\n",
    "        if 'ingredients' in recipe and recipe['ingredients']:\n",
    "            #Calculate how many ingredients match\n",
    "            recipe_ingredients = set(recipe['ingredients'])\n",
    "            input_ingredients = set(ingredients)\n",
    "            \n",
    "            common = len(recipe_ingredients.intersection(input_ingredients))\n",
    "            coverage = common / len(input_ingredients) if input_ingredients else 0\n",
    "            \n",
    "            matches.append({\n",
    "                'recipe': recipe,\n",
    "                'common_ingredients': common,\n",
    "                'coverage': coverage\n",
    "            })\n",
    "    \n",
    "    #Sort by coverage (higher is better)\n",
    "    matches.sort(key=lambda x: x['coverage'], reverse=True)\n",
    "    return [match['recipe'] for match in matches[:top_k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb0c237d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    #Initialize Firebase\n",
    "    cred_path = \"recipegen.json\"\n",
    "    storage_bucket = \"recipegen-710d0.firebasestorage.app\"\n",
    "    \n",
    "    try:\n",
    "        firebase_admin.get_app()\n",
    "    except ValueError:\n",
    "        cred = credentials.Certificate(cred_path)\n",
    "        firebase_admin.initialize_app(cred, {\n",
    "            \"storageBucket\": storage_bucket\n",
    "        })\n",
    "    \n",
    "    firestore_client = firestore.client()\n",
    "    \n",
    "    train_recipes, val_recipes, ingredient_to_idx = prepare_data_from_firebase(\n",
    "        firestore_client, \n",
    "        test_size=0.2\n",
    "    )\n",
    "    \n",
    "    #Data transforms\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "        transforms.ToImage(), \n",
    "        transforms.ToDtype(torch.float32, scale=True),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToImage(), \n",
    "        transforms.ToDtype(torch.float32, scale=True),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    #Create datasets\n",
    "    train_dataset = RecipeImageDataset(\n",
    "        recipes_data=train_recipes,\n",
    "        ingredient_mapping=ingredient_to_idx,\n",
    "        transform=train_transform\n",
    "    )\n",
    "    \n",
    "    val_dataset = RecipeImageDataset(\n",
    "        recipes_data=val_recipes,\n",
    "        ingredient_mapping=ingredient_to_idx,\n",
    "        transform=val_transform\n",
    "    )\n",
    "    \n",
    "    #Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=32, \n",
    "        shuffle=True, \n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=32, \n",
    "        shuffle=False, \n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    #Create model\n",
    "    num_ingredients = len(ingredient_to_idx)\n",
    "    model = IngredientRecognition(num_ingredients)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    #Define loss and optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    #Train model\n",
    "    trained_model = train_model(\n",
    "        model, \n",
    "        train_loader, \n",
    "        val_loader, \n",
    "        criterion, \n",
    "        optimizer, \n",
    "        num_epochs=15,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    #Save model\n",
    "    torch.save({\n",
    "        'model_state_dict': trained_model.state_dict(),\n",
    "        'ingredient_to_idx': ingredient_to_idx,\n",
    "        'idx_to_ingredient': {idx: ingredient for ingredient, idx in ingredient_to_idx.items()}\n",
    "    }, 'food_recognition_model.pth')\n",
    "    \n",
    "    print(\"Model training complete and saved to food_recognition_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb292d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9768 recipes for training\n",
      "Loaded 2443 recipes for testing\n",
      "Total unique ingredients: 67176\n",
      "Dataset created with 9768 recipes\n",
      "Total unique ingredients: 67176\n",
      "Dataset created with 2443 recipes\n",
      "Total unique ingredients: 67176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 - Training:   0%|          | 0/306 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
